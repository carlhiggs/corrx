---
title: "Corrx: Classical Twin Study Power Calculator and Simulation Reference"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: fill
    source_code: embed
    theme: cosmo
runtime: shiny

---

```{r global, include=FALSE}
# Carl Higgs, Jess Tyler, Katrina Scurrah, Enes Makalic 2019

library(flexdashboard)
library(knitr)
library(shiny)
library(ggplot2)
library(scales)
library(dplyr)
library(reshape2)
library(data.table)
library(magrittr)
library(shinyWidgets)

corrx_1k_sim <-read.csv("corrx_1k_subset.csv",  header = TRUE, stringsAsFactors=FALSE) 
  
```



About
=========================

<b>About this application</b>

This application is intended to help researchers estimate the power and sample size required for their classical twin study design. 

Parameters that affect the power of your twin study include: 

<ul>
<li>Number of twin pairs</li>
<li>The ratio of MZ to DZ pairs  </li>
<li>The estimated correlation for MZ pairs (monozygotic twins)</li>
<li>The estimated correlation for DZ pairs (dizygotic twins)</li>
<li>Whether your data are normally distributed or skewed</li>
</ul>


Variations to these parameters will change the required sample size for your study. The following calculator offered in this application allows different variations of these parameters to be explored so a more informed sample size target can be used to help guide recruitment resources. 

<b>Directions for use</b>

Go to the next tab titled “Twin Study Power Calculator”

In the scenario box on the left-hand side: 
<ul>
<li>Select the maximum possible number of MZ and DZ twin pairs. If unsure select a reasonable number and adjust accordingly to ensure the graph reaches appropriate power.</li>
<li>Input your estimated MZ pair and DZ pair correlations.</li>
<li>Select your target power</li>
<li>Select the variable distribution that is expected. Note: the skewed distributions are not strictly accurate but provide a rough example of how skewedness impacts power.</li>
</ul>

Outputs:

<ul>
<li>Graph 1: Power by sample size shows the number of twin pairs needed (x-axis) for the desired power (y-axis). Take note the number of pairs to reach your desired target power.</li>
<li>Graph 2: Power by ratio shows the power (y-axis) given the max sample size selected across a range of MZ to DZ pair ratios.</li>
<li>table 1: Power by correlation gives a snapshot of the data behind the simulation. You can see the exact power estimates per change in the difference between MZ pair and DZ pair correlations.</li>
</ul>

Adjust your parameters as you like and see the shift in power and sample size on the graphs. 

<b>Simulation notes</b>

The analytical method used for this simulation was the Fisher z test. 

A fixed alpha of 0.05 is used in this simulation. 

The skewed distributions are not strictly accurate but provide a rough example of how skewedness impacts power. 

<b>Acknowledgements</b>

This application was developed by Carl Higgs as part of his MBiostat research project in collaboration with academic staff at the Centre of Epidemiology and Biostatistics and Twins Research Australia at the University of Melbourne.


Twin Study Power Calculator
===========================

Inputs {.sidebar}
-----------------------------------------------------------------------
An interactive calculator of power for estimating the power and sample size required for their classical twin study design. 

Twins Research Australia, 2019.
```{r}
# Sample size (x) vs power (y), as for Stata graphs/previous version of app
# shiny inputs defined here
hr()

sliderTextInput("mz_n","Number of MZ twins (n1)",
                choices=c(15,30,60,120,240,480,960),selected=60, grid = T)
sliderInput("rho1", "Estimated correlation in MZ twins:",min=0.1, max=.9, value=0.7, step=0.1)

sliderTextInput("dz_n","Number of DZ twins (n2)",
                choices=c(15,30,60,120,240,480,960),selected=60, grid = T)
sliderInput("rho2", "Estimated correlation in DZ twins:",min=0.1, max=.9, value=0.2, step=0.1)

selectInput("power", "Select target power proportion", choices =c(.8, .9) ,selected = .8)
selectInput("skewness", "Select variable skewness: ", choices =c('normal', 'mild', 'extreme') ,selected = 'normal')

observeEvent(input$rho1,{

  if((input$rho1 > input$rho2)&&(input$rho1>0.1)) {
    val = NULL
  } 
  else if(input$rho1>0.1) {
    val = input$rho1-0.1
  }
  else {
    val = input$rho1
  }
  updateSliderInput(session, "rho2",min=0.1, max=input$rho1, value = val, step=0.1)
})
```


```{r}
mydata <- reactive({
    # Model Parameters:
      n_mz      <- input$mz_n
      n_dz      <- input$dz_n
      n         <- n_mz + n_dz
      ratio     <- n_mz/n_dz
      r1        <- input$rho1
      r2        <- input$rho2
      rdiff     <- r1 - r2
      maxn      <- n
      mzdz      <- ratio
      # alpha     <- input$alpha
      sidedness <- 2
      # method    <- input$method
      method    <- "pearson"
      # Step 1: calculate Fisher's Z
      z1        <- atanh(r1)
      z2        <- atanh(r2)
      # Step    2: take difference
      zdiff     <- z1-z2
      # Step    3: calculate standard errmzor and test statistic
      tot_n         <- 15:maxn
      mzdz_vec <- seq(0,10,0.01)
      # n_p1         <- cbind(mz = tot_n*mzdz,dz = tot_n*(1-mzdz))
      n_p1         <- cbind(mz = tot_n/(mzdz+1)*mzdz,dz = tot_n/(mzdz+1))
      n_p2         <- cbind(mz = maxn/(mzdz_vec+1)*mzdz_vec,dz = maxn/(mzdz_vec+1))
      z_se_p1      <- sqrt(rowSums(1/(n_p1-3)))
      z_se_p2      <- sqrt(rowSums(1/(n_p2-3)))
      z_test_p1    <- zdiff/z_se_p1
      z_test_p2    <- zdiff/z_se_p2
      # optionally return p-value for observing diff at least this large under H0
      # z_p    <- sidedness*pnorm(-abs(z_test))
      z_ref    <- qnorm(1-0.05/2)
      z_power1a <- 1-pnorm(z_ref[1] - abs(z_test_p1))
      z_power1b <- 1-pnorm(z_ref[2] - abs(z_test_p1))
      z_power1  <- rbind(cbind(z_power1a,z_ref[1]),cbind(z_power1b,z_ref[2]))
      z_power2a <- 1-pnorm(z_ref[1] - abs(z_test_p2))
      z_power2b <- 1-pnorm(z_ref[2] - abs(z_test_p2))
      z_power2  <- rbind(cbind(z_power2a,z_ref[1]),cbind(z_power2b,z_ref[2]))
      colnames(z_power1) <- colnames(z_power2) <- c("power","ref")
      
    # Collect and output results
    params1 <- paste0("MZ:DZ ratio: ",mzdz,"; rho_mz: ",r1,"; rho_dz: ",r2,"; delta: ",rdiff)
    params2 <- paste0("N: ",maxn,"; rho_mz: ",r1,"; rho_dz: ",r2,"; delta: ",rdiff)
    data1   <- cbind(n = tot_n,mzdz = mzdz,        mz = n_p1[,1],dz = n_p1[,2] , power1 = z_power1)
    data2   <- cbind(n = maxn, mzdz_vec = mzdz_vec,mz = n_p2[,1],dz = n_p2[,2] , power2 = z_power2)
    list(data1 =data1, 
         data2 = data2, 
         params1 = params1,
         params2 = params2 )
    })
scale <- function(x) sprintf("%.1f", x)
```


Row {.tabset .tabset-fade}
-------------------------------------

### Power by sample size

```{r}

renderPlot({
   p <- ggplot(as.data.frame(mydata()[["data1"]]),
        aes(x=n, y=power))
   p <- p +
     geom_line(aes(colour = as.character(round(ref,2))), size=1, alpha=.75,show.legend = FALSE) +
     ggtitle(paste0("Power estimate given parameters (",mydata()[["params1"]],")"))+
     scale_x_continuous(name="N")+
     scale_y_continuous(labels = scale, name="Power",limits = c(0.0,1.0), expand = c(0,0) ) 
   print(p)
  })

```


### Power by ratio

```{r}

renderPlot({
    p <- ggplot(as.data.frame(mydata()[["data2"]]),
                aes(x=mzdz_vec, y=power), log="x")
    p <- p +
      geom_line(aes(colour = as.character(round(ref,2))), size=1, alpha=.75,show.legend = FALSE) +
      ggtitle(paste0("Power estimate given parameters (",mydata()[["params2"]],")"))+
      scale_x_continuous(name="MZ:DZ ratio (log scale)", trans='log',limits = c(0.1,10),breaks=c(0.1,seq(0.2,1,0.2),seq(2,10,2)))+
      scale_y_continuous(labels = scale, name="Power",limits = c(0,1), expand = c(0,0) ) 
    print(p)
  })
```

### Power by correlation

```{r}

# filter data
obs <- reactive({
  corrx_1k_sim %>%
        filter(method  == "pearson" &
                 dist  == input$skewness    &
                 n1    == input$mz_n        &
                 n2    == input$dz_n        &
                 rho2  == input$rho2       
                 #fz    >= input$power
              ) %>%
        select(n1,n2,rho1,rho2, fz_nosim,fz)  %>%
        mutate(n = n1 + n2) %>%
        mutate(log_n = log2(n)) %>%
        mutate(rdiff = rho1 - rho2) %>%
        # select(n,log_n,rho1,fz_nosim,fz)  %>%
        select(n1,n2,n,rho1,rho2,rdiff,fz)  %>%
        reshape2::melt(
           id.vars=c("n1","n2","n","rho1","rho2","rdiff"),
          # measure.vars=c("fz_nosim","fz"),
          measure.vars=c("fz"),
          variable.name="test",
          value.name="power") %>%
        select(n1,n2,n,rho1,rho2,rdiff,power) %>%
        set_colnames(c("n1","n2","Total n","r_MZ","r_DZ","r_difference","Power"))
  })
```



```{r}

renderTable({
  obs()
})

# renderPlot({
#     n_mz      <- input$mz_n
#     n_dz      <- input$dz_n
#     n         <- n_mz + n_dz
#     ratio     <- n_mz/n_dz
#     ratio_str <- paste0(n_mz,'/',n_dz)
#     rho1        <- input$rho1
#     rho2        <- input$rho2
#     rdiff     <- rho1 - rho2
#     # fitted values (interpolated over observed)
#     fit <- data.table()
#       fit <- rbind(fit,
#                    cbind("n"    = min(obs()[,"n"]):max(obs()[,"n"]),
#                          "rho1" = splinefun(log2(obs()[,"n"]),
#                                             obs()[,"rho1"],
#                                             # method = "monoH.FC")(log2(min(obs()$n):max(obs()$n)))))
#                                             method = "monoH.FC")(log2(min(obs()$n):max(obs()$n)))))
#     fit$n <- as.integer(fit$n)
#     fit$rho1 <- as.double(fit$rho1)
#     # define plot title
#     title <- paste0("Power to detect difference in Pearson correlations >= ",input$power,
#                     ", by sample size and trait correlation in MZ twins\n",
#                     input$dist,"\n",
#                     "DZ rho: (",rho2,")",
#                     "; Mz to Dz ratio: ",ratio_str, "; sims: 1000")
#     # initialise plot
#     # p <- ggplot(NULL, aes(x = rho1, y = n, colour = test, group = test))+
#     p <- ggplot(NULL, aes(x = rho1, y = n))+
#       scale_y_continuous(trans='log2',bquote(N~(log[2]~scale)),
#                          breaks = unique(obs()$n),
#                          limits = c(30,1920)) +
#       scale_x_continuous(bquote(rho[MZ]),
#                          breaks = seq(0,1,0.1),
#                          limits = c(0,1)) +
#       geom_smooth(data = obs(),se=FALSE)  +
#       # scale_colour_discrete(name="Tests (req. n)"
#                             # ,
#                             # breaks=cross$test,
#                             # labels=cross$label
#                             # )  +
#       theme(panel.grid.minor = element_blank(),
#             panel.background = element_blank(),
#             axis.line = element_line(colour = "black")) +
#       ggtitle(title)
#     print(p)
#   })

```


